{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e97932-fec8-4d93-a80b-019ddd07f3df",
   "metadata": {},
   "source": [
    "# 1. 文档加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f13ce",
   "metadata": {},
   "source": [
    "## 1.1 PDF文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5a26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径\n",
    "loader = PyMuPDFLoader(\"../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf\")\n",
    "\n",
    "# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c036378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>， 该 PDF 一共包含 196 页\n"
     ]
    }
   ],
   "source": [
    "print(f\"载入后的变量类型为：{type(pages)}，\",  f\"该 PDF 一共包含 {len(pages)} 页\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848ddcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'file_path': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20230303170709-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "------\n",
      "查看该文档的内容:\n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第 1 章和第 2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力 (zhi) 争 (neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们 GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在 24 小时以内给您回复，超过 24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第 1 版）\n",
      "最新版 PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/re\n"
     ]
    }
   ],
   "source": [
    "page = pages[1]\n",
    "print(f\"每一个元素的类型：{type(page)}.\", \n",
    "    f\"该文档的描述性数据：{page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{page.page_content[0:1000]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc7350",
   "metadata": {},
   "source": [
    "## 1.2 MD文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca70bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "loader = UnstructuredMarkdownLoader(\"../QA_Project/data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f68c7e-58da-4c11-bedd-8fc047977fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入后的变量类型为：<class 'list'>， 该 Markdown 一共包含 1 页\n"
     ]
    }
   ],
   "source": [
    "print(f\"载入后的变量类型为：{type(pages)}，\",  f\"该 Markdown 一共包含 {len(pages)} 页\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5004eed-1e4e-41f8-a7e2-0d890945e2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../QA_Project/data_base/knowledge_db/prompt_engineering/1. 简介 Introduction.md'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "第一章 简介\n",
      "\n",
      "欢迎来到面向开发者的提示工程部分，本部分内容基于吴恩达老师的《Prompt Engineering for Developer》课程进行编写。《Prompt Engineering for Developer》课程是由吴恩达老师与 OpenAI 技术团队成员 Isa Fulford 老师合作授课，Isa 老师曾开发过受欢迎的 ChatGPT 检索插件，并且在教授 LLM （Large Language Model， 大语言模型）技术在产品中的应用方面做出了很大贡献。她还参与编写了教授人们使用 Prompt 的 OpenAI cookbook。我们希望通过本模块的学习，与大家分享使用提示词开发 LLM 应用的最佳实践和技巧。\n",
      "\n",
      "网络上有许多关于提示词（Prompt， 本教程中将保留该术语）设计的材料，例如《30 prompts everyone has to know》之类的文章，这些文章主要集中在 ChatGPT 的 Web 界面上，许多人在使用它执行特定的、通常是一次性的任务。但我们认为，对于开发人员，大语言模型（LLM） 的更强大功能是能通过 API 接口调用，从而快速构建软件应用程序。实际上，我们了解到 DeepLearning.AI 的姊妹公司 AI Fund 的团队一直在与许多初创公司合作，将这些技术应用于诸多应用程序上。很兴奋能看到 LLM API 能够让开发人员非常快速地构建应用程序。\n",
      "\n",
      "在本模块，我们将与读者分享提升大语言模型应用效果的各种技巧和最佳实践。书中内容涵盖广泛，包括软件开发提示词设计、文本总结、推理、转换、扩展以及构建聊天机器人等语言模型典型应用场景。我们衷心希望该课程能激发读者的想象力，开发出更出色的语言模型应用。\n",
      "\n",
      "随着 LLM 的发展，其大致可以分为两种类型，后续称为基础 LLM 和指令微调（Instruction Tuned）LLM。基础LLM是基于文本训练数据，训练出预测下一个单词能力的模型。其通常通过在互联网和其他来源的大量数据上训练，来确定紧接着出现的最可能的词。例如，如果你以“从前，有一只独角兽”作为 Prompt ，基础 LLM 可能会继续预测“她与独角兽朋友共同生活在一片神奇森林中”。但是，如果你以“法国的首都是什么”为 Prompt ，则基础 LLM 可能会根据互联网上的文章，将回答预测为“法国最大的城市是什么？法国的人口是多少？”，因为互联网上的文章很可能是有关法国国家的问答题目列表。\n",
      "\n",
      "与基础语言模型不同，指令微调 LLM 通过专门的训练，可以更好地理解并遵循指令。举个例子，当询问“法国的首都是什么？”时，这类模型很可能直接回答“法国的首都是巴黎”。指令微调 LLM 的训练通常基于预训练语言模型，先在大规模文本数据上进行预训练，掌握语言的基本规律。在此基础上进行进一步的训练与微调（finetune），输入是指令，输出是对这些指令的正确回复。有时还会采用RLHF（reinforcement learning from human feedback，人类反馈强化学习）技术，根据人类对模型输出的反馈进一步增强模型遵循指令的能力。通过这种受控的训练过程。指令微调 LLM 可以生成对指令高度敏感、更安全可靠的输出，较少无关和损害性内容。因此。许多实际应用已经转向使用这类大语言模型。\n",
      "\n",
      "因此，本课程将重点介绍针对指令微调 LLM 的最佳实践，我们也建议您将其用于大多数使用场景。当您使用指令微调 LLM 时，您可以类比为向另一个人提供指令（假设他很聪明但不知道您任务的具体细节）。因此，当 LLM 无法正常工作时，有时是因为指令不够清晰。例如，如果您想问“请为我写一些关于阿兰·图灵( Alan Turing )的东西”，在此基础上清楚表明您希望文本专注于他的科学工作、个人生活、历史角色或其他方面可能会更有帮助。另外您还可以指定回答的语调， 来更加满足您的需求，可选项包括专业记者写作，或者向朋友写的随笔等。\n",
      "\n",
      "如果你将 LLM 视为一名新毕业的大学生，要求他完成这个任务，你甚至可以提前指定他们应该阅读哪些文本片段来写关于阿兰·图灵的文本，这样能够帮助这位新毕业的大学生更好地完成这项任务。本书的下一章将详细阐释提示词设计的两个关键原则：清晰明确和给予充足思考时间。\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "print(f\"每一个元素的类型：{type(page)}.\", \n",
    "    f\"该文档的描述性数据：{page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{page.page_content[0:]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636454fa-a56d-4f95-9cd8-03d3a302dffd",
   "metadata": {},
   "source": [
    "## 1.3 视频文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06ad1c-c100-43b9-a996-bf5ecbd8acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频文件转写\n",
    "!whisper ../QA_Project/data_base/knowledge_db/easy_rl/强化学习入门指南.mp4 --model large --language zh --output_dir ../QA_Project/data_base/knowledge_db/easy_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057c3af7-51bd-4e0f-b53e-473da94537ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "# 加载转写得到的txt文件\n",
    "loader = UnstructuredFileLoader(\"../QA_Project/data_base/knowledge_db/easy__rl/强化学习入门指南.txt\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4632e618-c63d-48f2-be3c-604219f61718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../QA_Project/data_base/knowledge_db/easy__rl/强化学习入门指南.txt'}\n",
      "------\n",
      "查看该文档的内容:\n",
      "B站的小伙伴们好\n",
      "\n",
      "我是蘑菇书1.2.2强化学习教程的作者之一王奇\n",
      "\n",
      "将来有给大家一个强化学习的入门指南\n",
      "\n",
      "本次入门指南基于蘑菇书1.2.2强化学习教程\n",
      "\n",
      "本书的作者目前都是DIY成员\n",
      "\n",
      "也都是书在读\n",
      "\n",
      "下面去介绍每个作者\n",
      "\n",
      "我是王奇\n",
      "\n",
      "目前就留于中国科研大学\n",
      "\n",
      "营业方向是深度学习\n",
      "\n",
      "居然视觉以及数据挖掘\n",
      "\n",
      "杨玉云目前就留于清华大学\n",
      "\n",
      "他的营业方向为施工数据挖掘\n",
      "\n",
      "智能创开系统以及深度学习\n",
      "\n",
      "张继目前就留于北京大学\n",
      "\n",
      "他的营业方向为强化学习记忆人\n",
      "\n",
      "接下来开始真实的分享\n",
      "\n",
      "本次分享分为三部分\n",
      "\n",
      "第一部分为什么要学习强化学习\n",
      "\n",
      "第二部分\n",
      "\n",
      "为什么让本书来学\n",
      "\n",
      "第三部分\n",
      "\n",
      "这本书怎么学最高效\n",
      "\n",
      "首先讲一下\n",
      "\n",
      "为什么要学习强化学习\n",
      "\n",
      "我们先聊聊一下\n",
      "\n",
      "强化学习的基本概念\n",
      "\n",
      "强化学习用来学习\n",
      "\n",
      "如果做出一系列好的决策\n",
      "\n",
      "而人工智能的基本挑战是\n",
      "\n",
      "学习在不确定的情况下\n",
      "\n",
      "做出好的决策\n",
      "\n",
      "这边我指个例子\n",
      "\n",
      "比如你想让一个小孩学会走路\n",
      "\n",
      "他就需要通过不断尝试来发现\n",
      "\n",
      "怎么走比较好\n",
      "\n",
      "怎么走最快\n",
      "\n",
      "强化学习的交互过程\n",
      "\n",
      "可以通过这张图来表示\n",
      "\n",
      "强化学习由智能体和环境两部分组成\n",
      "\n",
      "在强化学习过程中\n",
      "\n",
      "智能体与环境一直在交互\n",
      "\n",
      "智能体在环境中\n",
      "\n",
      "或者某个状态后\n",
      "\n",
      "它会利用各个状态输出一个动作\n",
      "\n",
      "这个动作也被称为决策\n",
      "\n",
      "然而这个动作会被在环境中执行\n",
      "\n",
      "环境会根据智能体采取的动作\n",
      "\n",
      "来输出下一个状态\n",
      "\n",
      "以及当前这个动作的结果\n",
      "\n",
      "这个动作带来的奖励\n",
      "\n",
      "整体它的目的呢\n",
      "\n",
      "就是尽可能的多的\n",
      "\n",
      "尽可能多的在环境中获得奖励\n",
      "\n",
      "强化学习的应用非常广泛\n",
      "\n",
      "比如说我们可以使用强化学习来玩游戏\n",
      "\n",
      "玩游戏的话可以玩这种电子游戏\n",
      "\n",
      "也可以玩这种围棋游戏\n",
      "\n",
      "围棋游戏中比较出名的一个\n",
      "\n",
      "强化学习的一个算法\n",
      "\n",
      "就是二八够\n",
      "\n",
      "此外我们可以使用强化学习来控制机翼人\n",
      "\n",
      "以及来实践助理交通\n",
      "\n",
      "另外还可以使用强化学习来更好地给我们做推进\n",
      "\n",
      "接下来就到第二部分\n",
      "\n",
      "也就是为什么要使用本书来学习强化学习\n",
      "\n",
      "这部分其实也就是讲魔鬼书它出版的一些故事\n",
      "\n",
      "就当时我在学习强化学习的时候\n",
      "\n",
      "搜集了一些资料\n",
      "\n",
      "然后我发现呢\n",
      "\n",
      "这些资料都有点灰色难懂\n",
      "\n",
      "并不是那么容易的上手\n",
      "\n",
      "于是我开始到网上\n",
      "\n",
      "搜索一些公开课来学习\n",
      "\n",
      "首先我搜到的是\n",
      "\n",
      "就女红衣老师的一些公开课\n",
      "\n",
      "很多人就是入门生物学习和机器学习的第一门课\n",
      "\n",
      "其实就是女红衣老师的课\n",
      "\n",
      "然后女红衣\n"
     ]
    }
   ],
   "source": [
    "page = pages[0]\n",
    "print(f\"每一个元素的类型：{type(page)}.\", \n",
    "    f\"该文档的描述性数据：{page.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{page.page_content[0:1000]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148252d-cfcc-45cf-be70-6db8439c7d00",
   "metadata": {},
   "source": [
    "# 2. 文档分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "605b75e1-b476-4cb4-b3c8-6e85332601e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入文本分割器\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c279c1b-8ed7-4452-b966-473680bf54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 知识库中单段文本长度\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "# 知识库中相邻文本重合长度\n",
    "OVERLAP_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed24d6b2-bfc8-4bd4-8bdb-c5e9af4b0433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['前言\\n“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\\n者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\\n导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\\n具体的推导细节。”\\n读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\\n老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\\n中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\\n等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\\n下学生”。\\n使用说明\\n• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\\n为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\\n• 对于初学机器学习的小白，西瓜书第 1 章和第 2 章的公式强烈不建议深究，简单过一下即可，等你学得',\n",
       " '有点飘的时候再回来啃都来得及；\\n• 每个公式的解析和推导我们都力 (zhi) 争 (neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\\n我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\\n• 若南瓜书里没有你想要查阅的公式，或者你发现南瓜书哪个地方有错误，请毫不犹豫地去我们 GitHub 的\\nIssues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\\n提交你希望补充的公式编号或者勘误信息，我们通常会在 24 小时以内给您回复，超过 24 小时未回复的\\n话可以微信联系我们（微信号：at-Sm1les）；\\n配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\\n在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第 1 版）\\n最新版 PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/re']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径\n",
    "loader = PyMuPDFLoader(\"./个人知识库问答助手项目/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf\")\n",
    "\n",
    "# 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "pages = loader.load()\n",
    "page = pages[1]\n",
    "\n",
    "# 使用递归字符文本分割器\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=OVERLAP_SIZE\n",
    ")\n",
    "text_splitter.split_text(page.page_content[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e12e7b6c-72f5-45a4-ae2c-bbb5bde85245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的文件数量：736\n"
     ]
    }
   ],
   "source": [
    "split_docs = text_splitter.split_documents(pages)\n",
    "print(f\"切分后的文件数量：{len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52b780ea-1bfe-4acf-9c6a-081821f5e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后的字符数（可以用来大致评估 token 数）：314114\n"
     ]
    }
   ],
   "source": [
    "print(f\"切分后的字符数（可以用来大致评估 token 数）：{sum([len(doc.page_content) for doc in split_docs])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065af49-4266-4a40-ad57-cd5db21dc2e0",
   "metadata": {},
   "source": [
    "# 3. 文档词向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521711e3-7c92-4cea-a209-e779eb9efa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中\n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "_ = load_dotenv('./个人知识库问答助手项目/.env')\n",
    "\n",
    "# 获取环境变量 OPENAI_API_KEY\n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfb509d0-b74f-41fb-a7be-7d7763266bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "embed = QianfanEmbeddingsEndpoint(qianfan_ak=wenxin_api_key,\n",
    "                                  qianfan_sk=wenxin_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e48a054f-92b7-4a85-b993-9aaaffe945b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [02-27 14:00:33] openapi_requestor.py:316 [t:140273667651392]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [02-27 14:00:33] oauth.py:207 [t:140273667651392]: trying to refresh access_token for ak `NSwW3Z***`\n",
      "[INFO] [02-27 14:00:33] oauth.py:220 [t:140273667651392]: sucessfully refresh access_token\n",
      "[INFO] [02-27 14:00:34] openapi_requestor.py:316 [t:140273667651392]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [02-27 14:00:34] openapi_requestor.py:316 [t:140273667651392]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "query1 = \"机器学习\"\n",
    "query2 = \"强化学习\"\n",
    "query3 = \"大语言模型\"\n",
    "\n",
    "# 通过对应的 embedding 类生成 query 的 embedding。\n",
    "emb1 = embed.embed_query(query1)\n",
    "emb2 = embed.embed_query(query2)\n",
    "emb3 = embed.embed_query(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90d06a4a-08b3-4180-b143-fadf270805b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e1c8b2a-334e-4b3e-8637-bd31f9aff8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将返回结果转成 numpy 的格式，便于后续计算\n",
    "emb1 = np.array(emb1)\n",
    "emb2 = np.array(emb2)\n",
    "emb3 = np.array(emb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bf84828-216b-4cb5-9f0b-24ba4e12c23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器学习 生成的为长度 384 的 embedding , 其前 30 个值为： [ 0.07372477  0.04308164  0.06009696  0.08222438 -0.00893692 -0.06472083\n",
      "  0.06742696 -0.03099382  0.02741196  0.04192897  0.02765232  0.03472115\n",
      " -0.00372011  0.02133289 -0.11319303 -0.02625875 -0.07696626 -0.03250607\n",
      " -0.0133418  -0.01006646 -0.03099925 -0.03255303 -0.02057586 -0.02834741\n",
      " -0.0209821   0.06166624  0.08892459  0.03607437  0.07001293  0.08593539]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{query1} 生成的为长度 {len(emb1)} 的 embedding , 其前 30 个值为： {emb1[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "092fbe05-a6f0-495e-af1a-ffcbb4d8f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器学习 和 强化学习 向量之间的点积为：0.5430676172783679\n",
      "机器学习 和 大语言模型 向量之间的点积为：0.31060549690417294\n",
      "强化学习 和 大语言模型 向量之间的点积为：0.24259322925436513\n"
     ]
    }
   ],
   "source": [
    "print(f\"{query1} 和 {query2} 向量之间的点积为：{np.dot(emb1, emb2)}\")\n",
    "print(f\"{query1} 和 {query3} 向量之间的点积为：{np.dot(emb1, emb3)}\")\n",
    "print(f\"{query2} 和 {query3} 向量之间的点积为：{np.dot(emb2, emb3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f47f2b78-e1c3-4f0d-a151-b75af6bde193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器学习 和 强化学习 向量之间的余弦相似度为：[[0.5430676]]\n",
      "机器学习 和 大语言模型 向量之间的余弦相似度为：[[0.31060546]]\n",
      "强化学习 和 大语言模型 向量之间的余弦相似度为：[[0.24259322]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{query1} 和 {query2} 向量之间的余弦相似度为：{cosine_similarity(emb1.reshape(1, -1) , emb2.reshape(1, -1) )}\")\n",
    "print(f\"{query1} 和 {query3} 向量之间的余弦相似度为：{cosine_similarity(emb1.reshape(1, -1) , emb3.reshape(1, -1) )}\")\n",
    "print(f\"{query2} 和 {query3} 向量之间的余弦相似度为：{cosine_similarity(emb2.reshape(1, -1) , emb3.reshape(1, -1) )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a396f71-a0d2-4ecb-8538-32519d95afb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
