{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298a4f97-44e4-4a8b-b709-7a9b97732a94",
   "metadata": {},
   "source": [
    "# 向量数据库介绍和使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04f8fa-45a5-42fa-9b4d-9adfa4b5d777",
   "metadata": {},
   "source": [
    "## 1. 向量数据库简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608be23a-e880-436d-b36d-5989fcc163a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d90163-37d4-445f-b258-06a9be707487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from QA_Project.project.embedding.zhipuai_embedding import ZhipuAIEmbeddings\n",
    "from langchain_community.llms import QianfanLLMEndpoint\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from QA_Project.project.llm.spark_llm import Spark_LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a18d37c-4548-4387-bee1-185648e0f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTPS_PROXY'] = 'http://192.168.8.94:10809'\n",
    "os.environ[\"HTTP_PROXY\"] = 'http://192.168.8.94:10809'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4ca214-31c5-40ac-9ac8-9c7522a71053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用前配置自己的 api 到环境变量中如\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "_ = load_dotenv('../QA_Project/.env')\n",
    "\n",
    "# 获取环境变量 \n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]\n",
    "spark_app_id = os.environ[\"spark_app_id\"]\n",
    "spark_api_key = os.environ[\"spark_api_key\"]\n",
    "spark_secret_key = os.environ[\"spark_secret_key\"]\n",
    "zhipuai_api_key = os.environ[\"ZHIPUAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d40400-af0d-4549-9a30-f2188ac5f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 PDF\n",
    "loaders_chinese = [\n",
    "    PyMuPDFLoader(\"../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf\") # 南瓜书\n",
    "    # 大家可以自行加入其他文件\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders_chinese:\n",
    "    docs.extend(loader.load())\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# 定义 Embeddings\n",
    "qianfan_embedding = QianfanEmbeddingsEndpoint(qianfan_ak=wenxin_api_key,\n",
    "                                  qianfan_sk=wenxin_secret_key) \n",
    "# embedding = HuggingFaceEmbeddings(model_name=\"moka-ai/m3e-base\", model_kwargs=model_kwargs)\n",
    "# spark_embedding = SparkLLMTextEmbeddings(spark_app_id=spark_app_id, spark_api_key=spark_api_key, spark_api_secret=spark_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2cc6e3-c1af-47ed-afd2-d9cd0769372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = '../QA_Project/data_base/vector_db/test_chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36191fea-8bf9-4813-8f28-2c2bbee6a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf '../QA_Project/data_base/vector_db/test_chroma'  # 删除旧的数据库文件（如果文件夹中有文件的话），window电脑请手动删除"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a1559-cd75-4f2d-bcd0-9fdb23b30394",
   "metadata": {},
   "source": [
    "## 2. 构建chroma向量库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ef4a3d-8fad-4333-a769-1dfe35014845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-04 11:49:33] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:33] oauth.py:207 [t:140278941804352]: trying to refresh access_token for ak `NSwW3Z***`\n",
      "[INFO] [03-04 11:49:34] oauth.py:220 [t:140278941804352]: sucessfully refresh access_token\n",
      "[INFO] [03-04 11:49:34] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:35] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:35] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:36] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:37] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-04 11:49:37] openapi_requestor.py:316 [t:140278941804352]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[:100], # 为了速度，只选择了前 100 个切分的 doc 进行生成。\n",
    "    embedding=qianfan_embedding,\n",
    "    persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42567f3-c126-4283-9580-0eafe7a81b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4039fc93-c17b-4081-a60d-435717c7b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载已经构建好的向量数据库\n",
    "# vectordb = Chroma(\n",
    "#     persist_directory=persist_directory,\n",
    "#     embedding_function=embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c05f9ea-54d3-4eb6-9716-482176f3a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：100\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fe921-bf3f-4cb9-9bde-96817c4bf386",
   "metadata": {},
   "source": [
    "## 3. 通过向量数据库检索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef806309-0a79-4ad9-826b-6940ec6dcf68",
   "metadata": {},
   "source": [
    "### 3.1 相似度检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd403808-19f5-4e2e-ab6e-bab920f30c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"什么是机器学习\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32e4105-f610-4e12-971e-d30682837392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-05 09:55:01] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-05 09:55:01] oauth.py:207 [t:140511338940224]: trying to refresh access_token for ak `NSwW3Z***`\n",
      "[INFO] [03-05 09:55:01] oauth.py:220 [t:140511338940224]: sucessfully refresh access_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "sim_docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fa627c-ce39-4510-a547-e6c0af71c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\n",
      "←_←\n",
      "第 12 章 计算学习理论\n",
      "136\n",
      "12.1 基础知识\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "136\n",
      "12.1.1 式 (12.1) 的解释\n",
      ". . . . . . . . . . . \n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\n",
      "←_←\n",
      "目录\n",
      "第 1 章 绪论\n",
      "1\n",
      "1.1\n",
      "引言 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.2\n",
      "基本术语\n",
      ". . . . . . . . . . . . . . . . . . \n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74301b01-db0d-436c-a857-a44f60da78ee",
   "metadata": {},
   "source": [
    "### 3.2 MMR检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca24fab1-1e9d-4bb1-9390-20d5b669be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-05 09:55:16] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /embeddings/embedding-v1\n"
     ]
    }
   ],
   "source": [
    "mmr_docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c33969e-345f-44fd-b8b4-92937ebb2566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 检索到的第0个内容: \n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我\n",
      "--------------\n",
      "MMR 检索到的第1个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\n",
      "←_←\n",
      "8.2.15 式 (8.19) 的推导\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "82\n",
      "8.2.16 AdaBoost 的个人推导 . . . . . . . . . . . . . . . . . . . . . . .\n",
      "--------------\n",
      "MMR 检索到的第2个内容: \n",
      "45\n",
      "5.5.3\n",
      "式 (5.22) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "45\n",
      "5.5.4\n",
      "式 (5.23) 的解释\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "45\n",
      "5.6\n",
      "深\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR 检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fc1ac-c245-4238-a88d-1218fc769d08",
   "metadata": {},
   "source": [
    "## 4.构造检索式问答链"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3ccb0-9504-4da0-8ddd-f7f35aa3b712",
   "metadata": {},
   "source": [
    "### 4.1 直接询问LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae76ef91-e516-47c2-94e9-8e1c5dacf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入检索式问答链\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89afc27e-6a50-454a-9203-4166838e6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = QianfanLLMEndpoint(qianfan_ak=wenxin_api_key,\n",
    "                                  qianfan_sk=wenxin_secret_key,temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f8e2bcb-1cac-4dc4-81c4-625d3f678593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 可以使用 HuggingFacePipeline 本地搭建大语言模型\n",
    "# model_id = 'THUDM/chatglm2-6b-int4' # 采用 int 量化后的模型可以节省硬盘占用以及实时量化所需的运算资源\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModel.from_pretrained(model_id, trust_remote_code=True).half().quantize(4).cuda()\n",
    "# model = model.eval()\n",
    "# pipe = pipeline(\n",
    "#     \"text2text-generation\",\n",
    "#     model=model, \n",
    "#     tokenizer=tokenizer, \n",
    "#     max_length=100\n",
    "# )\n",
    "\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "041ad0f6-8583-410f-acc6-75c5a037b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声明一个检索式问答链\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023df5e5-fff2-49f7-bdf8-cfe62466804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-05 09:55:41] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-05 09:55:42] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大语言模型的回答为：本知识库主要包含机器学习的基础知识，包括深度学习、层次聚类、降维与度量学习、特征选择与稀疏学习等内容。此外，还包含一些预备知识和符号约定。\n"
     ]
    }
   ],
   "source": [
    "# 可以以该方式进行检索问答\n",
    "question = \"本知识库主要包含什么内容\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(f\"大语言模型的回答为：{result['result']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b36ef-d1ed-425a-b856-2609987b50f8",
   "metadata": {},
   "source": [
    "### 4.2 结合prompt的提问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01d5e499-c9c5-41bd-9706-386419424177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"使用以下上下文片段来回答最后的问题。如果你不知道答案，只需说不知道，不要试图编造答案。答案最多使用三个句子。尽量简明扼要地回答。在回答的最后一定要说\"感谢您的提问！\"\n",
    "{context}\n",
    "问题：{question}\n",
    "有用的回答：\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cee3c61-2cc3-4bcf-ac90-b0f3e0c8b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688ada59-2775-4fcf-86e0-1f2b0a8216a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" 2025 年大语言模型效果最好的是哪个模型\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29d23f60-9e17-4f0a-a030-4e20c6a61b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-05 09:55:59] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-05 09:56:00] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 对问题的回答：根据给出的上下文片段，无法确定2025年大语言模型效果最好的是哪个模型。需要更多的信息才能回答这个问题。\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})\n",
    "print(f\"LLM 对问题的回答：{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aa90461-7831-4233-9ff7-b181164de63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库检索到的最相关的文档：page_content='15\\n2.5.1\\n式 (2.37) 到式 (2.42) 的推导 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n15\\n第 3 章 线性模型\\n18\\n3.1\\n基本形式\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2\\n线性回归\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2.1\\n属性数值化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2.2' metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 2, 'producer': 'xdvipdfmx (20200315)', 'source': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量数据库检索到的最相关的文档：{result['source_documents'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5661d647-fc80-4ba8-8bb9-ff96ec873507",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain2 = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"map_reduce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a47555-8c0c-4aaa-a2da-8e1bf100447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [03-05 09:59:49] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /embeddings/embedding-v1\n",
      "[INFO] [03-05 09:59:50] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n",
      "[INFO] [03-05 09:59:52] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n",
      "[INFO] [03-05 09:59:54] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n",
      "[INFO] [03-05 09:59:56] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n",
      "[INFO] [03-05 09:59:57] openapi_requestor.py:316 [t:140511338940224]: requesting llm api endpoint: /chat/eb-instant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 对问题的回答：无法回答。这段文字并未提及关于2025年大语言模型效果最好的是哪个模型的具体信息。\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain2({\"query\": question})\n",
    "print(f\"LLM 对问题的回答：{result['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfd7f7ed-e99f-4d8d-b8b1-c58869a09332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库检索到的最相关的文档：page_content='15\\n2.5.1\\n式 (2.37) 到式 (2.42) 的推导 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n15\\n第 3 章 线性模型\\n18\\n3.1\\n基本形式\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2\\n线性回归\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2.1\\n属性数值化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n18\\n3.2.2' metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 2, 'producer': 'xdvipdfmx (20200315)', 'source': '../QA_Project/data_base/knowledge_db/pumpkin_book/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量数据库检索到的最相关的文档：{result['source_documents'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea03ae5-5adf-4486-8f24-c229710910cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
